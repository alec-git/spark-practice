import org.apache.spark.api.java.JavaRDD
import org.apache.spark.SparkConf
import org.apache.spark.sql.Column
import org.apache.spark.sql.Dataset
import org.apache.spark.sql.Row
import org.apache.spark.sql.SQLContext
import java.io.Serializable
import java.util.Arrays
import java.util.List



val flightData2015 = spark.read.option("inferSchema", "true").option("header", "true").csv("C:/Users/alecg/Desktop/data/flight-data/csv/2015-summary.csv")

flightData2015.take(3)

spark.conf.set("spark.sql.shuffle.partitions", "5")
flightData2015.sort("count").take(2)

flightData2015.sort("count").explain()

spark.conf.set("spark.sql.shuffle.partitions", "5")

flightData2015.sort("count").take(2)

flightData2015.createOrReplaceTempView("flight_data_2015")

val sqlWay = spark.sql("""SELECT DEST_COUNTRY_NAME, count(1)FROM flight_data_2015GROUP BY DEST_COUNTRY_NAME""")
val dataFrameWay = flightData2015.groupBy("DEST_COUNTRY_NAME").count()

// sqlWay.explain()
dataFrameWay.explain()

spark.sql("SELECT max(count) from flight_data_2015").take(1)

flightData2015.select(max("count")).take(1)

val maxSql = spark.sql("""SELECT DEST_COUNTRY_NAME, sum(count) as destination_totalFROM flight_data_2015 GROUP BY DEST_COUNTRY_NAMEORDER BY sum(count) DESCLIMIT 5""")

// max.Sql.show()

flightData2015.groupBy("DEST_COUNTRY_NAME").sum("count").withColumnRenamed("sum(count", "destination_total").sort(desc("destination_total")).limit(5).show()

flightData2015.groupBy("DEST_COUNTRY_NAME").sum("count").withColumnRenamed("sum(count", "destination_total").sort(desc("destination_total")).limit(5).explain()
